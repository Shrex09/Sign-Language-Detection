This project is a Sign Language Detection designed to recognize and interpret commonly used signs in real time. 
It leverages machine learning and computer vision to enable communication by mapping gestures to meaningful expressions. 
Developed using Python,the project demonstrates a practical application of AI in promoting inclusivity and accessibility. 

Key features include:  
- Detection and interpretation of multiple sign gestures.  
- A user-friendly interface for interaction.  
- Potential for expansion to accommodate more gestures.  

This project includes libraries like opencv,mediapipe,numpy,os module to interact with the operating system.
One addtional tip is after you capture your datasets and you have to train your model for the detection you can use
teachable machine a experimental website by google to train your model and you can download tensorflow,keras model to integrate with your code!!
